# -*- coding: utf-8 -*-
"""WorkshopEmpKPIsPrediction-std.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1y-fvWW3e1uxSaeqLCYKZc1y-yE7W37IU

#  Workshop: Employee KPIs Prediction

Data source:
https://www.kaggle.com/datasets/sanjanchaudhari/employees-performance-for-hr-analytics/data

- In this workshop, you will learn to use Grid Search to find the best parameters

## Prepare Data
"""

import numpy as np
import pandas as pd

df_org = pd.read_csv("Uncleaned_employees_final_dataset.csv")

df = df_org.copy()
df.head()

df.shape

df.columns

# Iterate through each column and print unique values
for column in df.columns:
    unique_values = df[column].unique()
    print(f"'{column}': {unique_values}")

df = df.drop('employee_id',axis=1)

"""## Handle Missing Data"""

df.isna().sum()/len(df)*100

df['previous_year_rating'].mode()[0]

df['education'] = df['education'].fillna('None')
df['previous_year_rating'] = df['previous_year_rating'].fillna(df['previous_year_rating'].mode()[0])

df.isna().sum()/len(df)*100

"""## Categotical Encoding"""

df.info()

df

#Encoding the object columns.
from sklearn.preprocessing import LabelEncoder
department_encoder = LabelEncoder().fit(df['department'])
region_encoder = LabelEncoder().fit(df['region'])
education_encoder = LabelEncoder().fit(df['education'])
gender_encoder = LabelEncoder().fit(df['gender'])
recruitment_channel_encoder = LabelEncoder().fit(df['recruitment_channel'])

df['department'] = department_encoder.transform(df['department'])
df['region'] = region_encoder.transform(df['region'])
df['education'] = education_encoder.transform(df['education'])
df['gender'] = gender_encoder.transform(df['gender'])
df['recruitment_channel'] = recruitment_channel_encoder.transform(df['recruitment_channel'])

"""## Correlation of features  """

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

# Assuming your DataFrame is named df
# If not, replace df with the actual name of your DataFrame

# Calculate the correlation matrix
correlation_matrix = df.corr()

# Set up the matplotlib figure
plt.figure(figsize=(10, 8))

# Create a heatmap using seaborn to visualize the correlation matrix
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5)

# Show the plot
plt.title('Correlation Matrix of Features')
plt.show()



"""## Plot in 2 Dimensions using PCA"""

from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler

features = ['department','region','education', 'gender', 'recruitment_channel',
            'no_of_trainings', 'age', 'previous_year_rating',
            'length_of_service', 'awards_won', 'avg_training_score']
X = df[features]
y = df['KPIs_met_more_than_80']

# Standardize the features
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Apply PCA
pca = PCA(n_components=2)
X_pca = pca.fit_transform(X_scaled)

# Create a DataFrame with PCA components and target variable
pca_df = pd.DataFrame(data={'PCA1': X_pca[:, 0], 'PCA2': X_pca[:, 1], 'target': y})

# Plot the PCA components
plt.figure(figsize=(10, 8))
sns.scatterplot(x='PCA1', y='PCA2', hue='target', data=pca_df, palette='viridis', s=50)
plt.title('PCA of Features Colored by Target Variable')
plt.xlabel('Principal Component 1')
plt.ylabel('Principal Component 2')
plt.legend(title='Target', loc='upper right')
plt.show()





"""## Select Feature and Target"""

df.columns

features = ['department','region','education', 'gender', 'recruitment_channel',
            'no_of_trainings', 'age', 'previous_year_rating',
            'length_of_service', 'awards_won', 'avg_training_score']

X = df[features]
y = df['KPIs_met_more_than_80']

X.head()

"""## Train/Test Data Split"""

from sklearn.model_selection import train_test_split
# Split data into features and target
# Split data into train and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)





"""## Alg1: RandomForest

### Grid Search the best parameters
"""

from sklearn.model_selection import GridSearchCV
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier

# Define the pipeline
model = Pipeline(steps=[
    ('scaler', StandardScaler()),  # Normalization step
    ('rf', RandomForestClassifier(random_state=42))  # You can replace this with any other classifier
])

param_grid = {
    'rf__n_estimators': [10, 100, 1000],
    'rf__max_depth': [None, 10, 20],
}


# Create GridSearchCV
grid_search = GridSearchCV(model, param_grid, cv=5, scoring='accuracy')  # You can adjust cv (cross-validation) as needed

# Fit the pipeline with GridSearchCV
grid_search.fit(X_train, y_train)

# Access the best parameters and best estimator
best_params = grid_search.best_params_
best_estimator = grid_search.best_estimator_

from google.colab import drive
drive.mount('/content/drive')



print(best_params)
print(best_estimator)

"""### Training to Create Model with the Best Parameter"""

from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier

# Define the pipeline
model = Pipeline(steps=[
    ('scaler', StandardScaler()),  # Normalization step
    ('rf', RandomForestClassifier(random_state=42, max_depth=10, n_estimators=1000))  # You can replace this with any other classifier
])

# Fit the pipeline
model.fit(X_train, y_train)

"""### Testing / Evaluation"""

from sklearn.metrics import confusion_matrix, classification_report
import matplotlib.pyplot as plt
import seaborn as sns


# Make predictions
y_pred = model.predict(X_test)

summary_eval = classification_report(y_test,y_pred,digits=4)
print(summary_eval)

# Calculate the confusion matrix
cm = confusion_matrix(y_test, y_pred)

# Plot the confusion matrix using seaborn heatmap
plt.figure(figsize=(6, 4))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', )
plt.title('Confusion Matrix: Random Forest')
plt.xlabel('Predicted')
plt.ylabel('True')
# Save the plot as an image file (e.g., PNG)
plt.savefig('confusion_matrix_randforest.png')

plt.show()



"""## Alg2: XGBoost

### Grid Search the best parameters
"""

from sklearn.model_selection import GridSearchCV
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler
from xgboost import XGBClassifier

# Define the pipeline
model = Pipeline(steps=[
    ('scaler', StandardScaler()),  # Normalization step
    ('xgb', XGBClassifier(random_state=42))  # You can replace this with any other classifier
])


param_grid = {
    'xgb__n_estimators': [50, 100, 150],
    'xgb__max_depth': [3, 5, 7],
    'xgb__learning_rate': [0.01, 0.1, 0.2]
}


# Create GridSearchCV
grid_search = GridSearchCV(model, param_grid, cv=5, scoring='accuracy')  # You can adjust cv (cross-validation) as needed

# Fit the pipeline with GridSearchCV
grid_search.fit(X_train, y_train)

# Access the best parameters and best estimator
best_params = grid_search.best_params_
best_estimator = grid_search.best_estimator_

print(best_params)
print(best_estimator)



"""### Training to Create Model with the Best Parameter"""

from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler
from xgboost import XGBClassifier

# Define the pipeline
model = Pipeline(steps=[
    ('scaler', StandardScaler()),  # Normalization step
    ('xgb', XGBClassifier(random_state=42, max_depth=5,  n_estimators=50, learning_rate=0.1))  # You can replace this with any other classifier
])

# Fit the pipeline
model.fit(X_train, y_train)

"""### Testing / Evaluation"""

from sklearn.metrics import confusion_matrix, classification_report
import matplotlib.pyplot as plt
import seaborn as sns


# Make predictions
y_pred = model.predict(X_test)

summary_eval = classification_report(y_test,y_pred,digits=4)
print(summary_eval)

# Calculate the confusion matrix
cm = confusion_matrix(y_test, y_pred)

# Plot the confusion matrix using seaborn heatmap
plt.figure(figsize=(6, 4))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', )
plt.title('Confusion Matrix: XGBoost')
plt.xlabel('Predicted')
plt.ylabel('True')
# Save the plot as an image file (e.g., PNG)
plt.savefig('confusion_matrix_xgb.png')

plt.show()

"""## Alg3: ...

### Grid Search the best parameters
"""

from sklearn.model_selection import GridSearchCV
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.neighbors import KNeighborsClassifier
...

# Define the pipeline
model = Pipeline(steps=[
    ('scaler', StandardScaler()),  # Normalization step
    ('knn', KNeighborsClassifier())  # You can replace this with any other classifier
])


param_grid = {
    'knn__n_neighbors': [3, 5, 7, 9]   #number of neighbors
}


# Create GridSearchCV
grid_search = GridSearchCV(model, param_grid, cv=5, scoring='accuracy')  # You can adjust cv (cross-validation) as needed

# Fit the pipeline with GridSearchCV
grid_search.fit(X_train, y_train)

# Access the best parameters and best estimator
best_params = grid_search.best_params_
best_estimator = grid_search.best_estimator_

print(best_params)
print(best_estimator)



"""### Training to Create Model with the Best Parameter"""

from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.neighbors import KNeighborsClassifier

# Define the pipeline
model = Pipeline(steps=[
    ('scaler', StandardScaler()),  # Normalization step
     ('knn', KNeighborsClassifier(n_neighbors=9))  # You can replace this with any other classifier
])

# Fit the pipeline
model.fit(X_train, y_train)

"""### Testing / Evaluation"""

from sklearn.metrics import confusion_matrix, classification_report
import matplotlib.pyplot as plt
import seaborn as sns


# Make predictions
y_pred = model.predict(X_test)

summary_eval = classification_report(y_test,y_pred,digits=4)
print(summary_eval)

# Calculate the confusion matrix
cm = confusion_matrix(y_test, y_pred)

# Plot the confusion matrix using seaborn heatmap
plt.figure(figsize=(6, 4))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', )
plt.title('Confusion Matrix: ...')
plt.xlabel('Predicted')
plt.ylabel('True')
# Save the plot as an image file (e.g., PNG)
plt.savefig('confusion_matrix_xxx.png')

plt.show()

"""## Select the Best Model to Create on All Data, i.e., (X,y), and Save Model

"""

from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler
...

# Define the pipeline
model = Pipeline(steps=[
    ('scaler', StandardScaler()),  # Normalization step
    ('..', ...)  # You can replace this with any other classifier
])

# Fit the pipeline
model.fit(X, y)

import pickle
# Create a tuple or any container object with your variables
data_to_save = (model, department_encoder, region_encoder, education_encoder, gender_encoder, recruitment_channel_encoder)

# Open a file in binary write mode
with open('model_kpi.pkl', 'wb') as file:
    # Save the container object
    pickle.dump(data_to_save, file)



"""## Load Model and Prediction

Kernel -> Restart Kernel..

### Load model
"""

import pickle
import pandas as pd

with open('model_kpi.pkl', 'rb') as file:
    # Load the data from the file
    model, department_encoder, region_encoder, education_encoder, gender_encoder, recruitment_channel_encoder = pickle.load(file)

"""### New data"""

# Get user input for each variable
x_new =  pd.DataFrame()
x_new['department'] = ['Technology']
x_new['region'] = ['region_26']
x_new['education'] = ['Bachelors']
x_new['gender'] = ['m']
x_new['recruitment_channel'] = ['sourcing']
x_new['no_of_trainings'] = [1]
x_new['age'] = [24]
x_new['previous_year_rating'] = [2]
x_new['length_of_service'] = [1]
x_new['awards_won'] = [0]
x_new['avg_training_score'] = [77]

"""### Categorical Data Encoding"""

x_new['department'] = department_encoder.transform(x_new['department'])
x_new['region'] = region_encoder.transform(x_new['region'])
x_new['education'] = education_encoder.transform(x_new['education'])
x_new['gender'] = gender_encoder.transform(x_new['gender'])
x_new['recruitment_channel'] = recruitment_channel_encoder.transform(x_new['recruitment_channel'])

"""### Predicting"""

y_pred_new = model.predict(x_new)

result = y_pred_new

print('KPIs_met_more_than_80: ', result)

"""## Create file app_KPI.py"""

# Commented out IPython magic to ensure Python compatibility.
# %%writefile app_KPI.py
# 
# import streamlit as st
# import pandas as pd
# import numpy as np
# import matplotlib.pyplot as plt
# import seaborn as sns
# import pickle
# 
# # Load model and encoders
# with open('model_kpi.pkl', 'rb') as file:
#     model, department_encoder, region_encoder, education_encoder, gender_encoder, recruitment_channel_encoder = pickle.load(file)
# 
# # Load your DataFrame
# # Replace 'your_data.csv' with the actual file name or URL
# df = pd.read_csv('Uncleaned_employees_final_dataset.csv')
# df = df.drop('employee_id', axis=1)
# 
# # Streamlit App
# st.title('Employee KPIs App')
# 
# # Define a session state to remember tab selections
# if 'tab_selected' not in st.session_state:
#     st.session_state.tab_selected = 0
# 
# # Create tabs for prediction and visualization
# tabs = ['Predict KPIs', 'Visualize Data', 'Predict from CSV']
# selected_tab = st.radio('Select Tab:', tabs, index=st.session_state.tab_selected)
# 
# # Tab selection logic
# if selected_tab != st.session_state.tab_selected:
#     st.session_state.tab_selected = tabs.index(selected_tab)
# 
# # Tab 1: Predict KPIs
# if st.session_state.tab_selected == 0:
#     st.header('Predict KPIs')
# 
#     # User Input Form
#     department = st.selectbox('Department', department_encoder.classes_)
#     region = st.selectbox('Region', region_encoder.classes_)
#     education = st.selectbox('Education', education_encoder.classes_)
#     gender = st.radio('Gender', gender_encoder.classes_)
#     recruitment_channel = st.selectbox('Recruitment Channel', recruitment_channel_encoder.classes_)
#     no_of_trainings = st.slider('Number of Trainings', 1, 10, 1)
#     age = st.slider('Age', 18, 60, 30)
#     previous_year_rating = st.slider('Previous Year Rating', 1.0, 5.0, 3.0)
#     length_of_service = st.slider('Length of Service', 1, 20, 5)
#     awards_won = st.checkbox('Awards Won')
#     avg_training_score = st.slider('Average Training Score', 40, 100, 70)
# 
#     # Create a DataFrame for the user input
#     user_input = pd.DataFrame({
#         'department': [department],
#         'region': [region],
#         'education': [education],
#         'gender': [gender],
#         'recruitment_channel': [recruitment_channel],
#         'no_of_trainings': [no_of_trainings],
#         'age': [age],
#         'previous_year_rating': [previous_year_rating],
#         'length_of_service': [length_of_service],
#         'awards_won': [1 if awards_won else 0],
#         'avg_training_score': [avg_training_score]
#     })
# 
#     # Categorical Data Encoding
#     user_input['department'] = department_encoder.transform(user_input['department'])
#     user_input['region'] = region_encoder.transform(user_input['region'])
#     user_input['education'] = education_encoder.transform(user_input['education'])
#     user_input['gender'] = gender_encoder.transform(user_input['gender'])
#     user_input['recruitment_channel'] = recruitment_channel_encoder.transform(user_input['recruitment_channel'])
# 
#     # Predicting
#     prediction = model.predict(user_input)
# 
#     # Display Result
#     st.subheader('Prediction Result:')
#     st.write('KPIs_met_more_than_80:', prediction[0])
# 
# # Tab 2: Visualize Data
# elif st.session_state.tab_selected == 1:
#     st.header('Visualize Data')
# 
#     # Select condition feature
#     condition_feature = st.selectbox('Select Condition Feature:', df.columns)
# 
#     # Set default condition values
#     default_condition_values = ['Select All'] + df[condition_feature].unique().tolist()
# 
#     # Select condition values
#     condition_values = st.multiselect('Select Condition Values:', default_condition_values)
# 
#     # Handle 'Select All' choice
#     if 'Select All' in condition_values:
#         condition_values = df[condition_feature].unique().tolist()
# 
#     if len(condition_values) > 0:
#         # Filter DataFrame based on selected condition
#         filtered_df = df[df[condition_feature].isin(condition_values)]
# 
#         # Plot the number of employees based on KPIs
#         fig, ax = plt.subplots(figsize=(14, 8))
#         sns.countplot(x=condition_feature, hue='KPIs_met_more_than_80', data=filtered_df, palette='viridis')
#         plt.title('Number of Employees based on KPIs')
#         plt.xlabel(condition_feature)
#         plt.ylabel('Number of Employees')
#         st.pyplot(fig)
# 
# # Tab 3: Predict from CSV
# elif st.session_state.tab_selected == 2:
#     st.header('Predict from CSV')
# 
#     # Upload CSV file
#     uploaded_file = st.file_uploader("Upload CSV file", type=["csv"])
#     # uploaded_file
# 
#     if uploaded_file is not None:
#         # Read CSV file
#         csv_df_org = pd.read_csv(uploaded_file)
#         csv_df_org = csv_df_org.dropna()
#         # csv_df_org.columns
# 
#         csv_df = csv_df_org.copy()
#         csv_df = csv_df.drop('employee_id',axis=1)
# 
# 
# 
#          # Categorical Data Encoding
#         csv_df['department'] = department_encoder.transform(csv_df['department'])
#         csv_df['region'] = region_encoder.transform(csv_df['region'])
#         csv_df['education'] = education_encoder.transform(csv_df['education'])
#         csv_df['gender'] = gender_encoder.transform(csv_df['gender'])
#         csv_df['recruitment_channel'] = recruitment_channel_encoder.transform(csv_df['recruitment_channel'])
# 
# 
#         # Predicting
#         predictions = model.predict(csv_df)
# 
#         # Add predictions to the DataFrame
#         csv_df_org['KPIs_met_more_than_80'] = predictions
# 
#         # Display the DataFrame with predictions
#         st.subheader('Predicted Results:')
#         st.write(csv_df_org)
# 
#         # Visualize predictions based on a selected feature
#         st.subheader('Visualize Predictions')
# 
#         # Select feature for visualization
#         feature_for_visualization = st.selectbox('Select Feature for Visualization:', csv_df_org.columns)
# 
#         # Plot the number of employees based on KPIs for the selected feature
#         fig, ax = plt.subplots(figsize=(14, 8))
#         sns.countplot(x=feature_for_visualization, hue='KPIs_met_more_than_80', data=csv_df_org, palette='viridis')
#         plt.title(f'Number of Employees based on KPIs - {feature_for_visualization}')
#         plt.xlabel(feature_for_visualization)
#         plt.ylabel('Number of Employees')
#         st.pyplot(fig)
# 
#



"""## Deploy on Streamlit Sharing

https://share.streamlit.io/

https://github.com/


"""

# Commented out IPython magic to ensure Python compatibility.
# %%writefile requirements.txt
# 
# scikit-learn==1.2.2
# pandas
#

ls

